# -*- coding: utf-8 -*-
# UIæ”¹å–„ç‰ˆ (v3)
# - ã‚¿ãƒ–â‘ ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ï¼‰ã¨ã‚¿ãƒ–â‘¡ï¼ˆçµåˆï¼‰ã‚’ã€ŒSQLãƒ“ãƒ«ãƒ€ãƒ¼ã€ã‚¿ãƒ–ã«çµ±åˆ
# - SQLä¿å­˜æ©Ÿèƒ½ã€S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’å‰Šé™¤ã—ã€UIã‚’ç°¡ç´ åŒ–
# - æ“ä½œãƒ•ãƒ­ãƒ¼: [Step 1: ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©] -> [Step 2: æ¡ä»¶æŒ‡å®š] -> [Step 3: å®Ÿè¡Œ]
# - ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’å‹•çš„ã«è¿½åŠ ãƒ»å‰Šé™¤ã§ãã‚‹UIã«å¤‰æ›´
# - ãƒ•ã‚£ãƒ«ã‚¿UIã®ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤ºåŒ–
# - (v3) ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ãƒ•ã‚©ãƒ¼ãƒ ã‚’æ¨ªä¸¦ã³ã«å¤‰æ›´
# - (v3) çµåˆã‚¹ãƒ†ãƒƒãƒ—ã®å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’å³ç«¯ã«é…ç½®
# - (v3) SELECTå¥ã‚‚st.expanderã§å›²ã‚€

import streamlit as st
import pandas as pd
import datetime
import re
from io import BytesIO
import snowflake.connector
import zipfile
import csv
import io

# -------------------------------------------------
# ãƒšãƒ¼ã‚¸è¨­å®š
# -------------------------------------------------
st.set_page_config(page_title="ãƒ‡ãƒ¼ã‚¿é–²è¦§", layout="wide")

# è»½é‡ãƒ†ãƒ¼ãƒï¼ˆé…è‰²ãƒ»ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºï¼‰
st.markdown("""
<style>
:root {
  --accent: #2563EB;     /* ãƒœã‚¿ãƒ³ç­‰ã®ã‚¢ã‚¯ã‚»ãƒ³ãƒˆ */
  --ok: #16A34A;         /* æˆåŠŸ */
  --warn: #D97706;       /* è­¦å‘Š */
  --muted: #6B7280;      /* ã‚µãƒ–ãƒ†ã‚­ã‚¹ãƒˆ */
}
.block-container { padding-top: 1rem; }
h1, h2, h3 { font-weight: 600; }
div[data-testid="stMarkdownContainer"] code, pre code { font-size: 0.95rem; }
div.stButton > button[kind="primary"] {
  background: var(--accent); border-color: var(--accent);
}
div.stButton > button[disabled] { opacity: 0.5; cursor: not-allowed; }
div.stTabs [data-baseweb="tab"] { font-size: 0.95rem; }
.small-muted { color: var(--muted); font-size: 0.9rem; }
.badge { display:inline-block; padding: 0.1rem .5rem; border-radius: .4rem; font-size:.8rem; }
.badge-ok { background:#DCFCE7; color:#166534; }
.badge-warn { background:#FEF9C3; color:#854D0E; }
.badge-run { background:#DBEAFE; color:#1E40AF; }
hr { margin: .8rem 0; }
</style>
""", unsafe_allow_html=True)

# -------------------------------------------------
# è¨­å®šï¼ˆæ‹¡å¼µå¯èƒ½ãªå¯¾è±¡ã‚¹ã‚­ãƒ¼ãƒï¼‰
# -------------------------------------------------
TARGETS = [
    {"db": "TEST_DB", "schema": "TEST"},
]

# -------------------------------------------------
# å®šæ•°
# -------------------------------------------------
CSV_MAX = 50000   # CSV/TSV ã®ZIPåˆ†å‰²è¡Œæ•°
EXCEL_MAX = 50000 # Excelã®æœ€å¤§è¡Œæ•°

# -------------------------------------------------
# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
# -------------------------------------------------
# SQLãƒ“ãƒ«ãƒ€ãƒ¼ã‚¿ãƒ–ã®çŠ¶æ…‹
if "builder_base_table" not in st.session_state:
    st.session_state.builder_base_table = ""
if "builder_join_steps" not in st.session_state:
    st.session_state.builder_join_steps = []
if "builder_available_columns" not in st.session_state:
    # (ä¾‹: [{"fq_name": "TBL.COL", "table": "TBL", "column": "COL", "dtype": "VARCHAR"}, ...])
    st.session_state.builder_available_columns = []
if "builder_where_conditions" not in st.session_state: # å‹•çš„ãƒ•ã‚£ãƒ«ã‚¿ç”¨
    # (ä¾‹: [{"id": 1, "column": "TBL.COL", "operator": "=", "value": "abc"}, ...])
    st.session_state.builder_where_conditions = []
if "builder_where_next_id" not in st.session_state: # å‹•çš„ãƒ•ã‚£ãƒ«ã‚¿ç”¨
    st.session_state.builder_where_next_id = 0
if "builder_selected_columns" not in st.session_state:
    st.session_state.builder_selected_columns = []
if "builder_sql" not in st.session_state:
    st.session_state.builder_sql = ""
if "builder_df_preview" not in st.session_state:
    st.session_state.builder_df_preview = pd.DataFrame()
if "builder_df_for_download" not in st.session_state:
    st.session_state.builder_df_for_download = pd.DataFrame()


# -------------------------------------------------
# æ¥ç¶šãƒ»å…±é€šã‚¯ã‚¨ãƒªé–¢æ•°
# -------------------------------------------------
@st.cache_resource
def get_conn():
    """Snowflakeæ¥ç¶šã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³å†…ã§å†åˆ©ç”¨"""
    return snowflake.connector.connect()

def _normalize_params(params):
    """executeã«æ¸¡ã™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–ï¼ˆç©ºdictã‚’æ¸¡ã•ãªã„ï¼š252004å¯¾ç­–ï¼‰"""
    if params is None:
        return None
    if isinstance(params, (list, tuple)):
        return params if len(params) > 0 else None
    if isinstance(params, dict):
        return list(params.values()) if len(params) > 0 else None
    return [params]

@st.cache_data(ttl=600)
def run_query(sql: str, params=None) -> pd.DataFrame:
    """
    Snowflakeã«SQLã‚’æŠ•ã’ã¦DataFrameã‚’è¿”ã™ã€‚
    ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç„¡ã—ã¯ None ã‚’æ¸¡ã—ã€ç©ºdictã¯æ¸¡ã•ãªã„ï¼ˆ252004å¯¾ç­–ï¼‰ã€‚
    """
    with get_conn().cursor() as cur:
        cur.execute(sql, _normalize_params(params))
        try:
            return cur.fetch_pandas_all()  # Arrowãƒ™ãƒ¼ã‚¹ã§é«˜é€Ÿ
        except Exception:
            rows = cur.fetchall()
            cols = [c[0] for c in cur.description]
            return pd.DataFrame(rows, columns=cols)

# -------------------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# -------------------------------------------------
@st.cache_data(ttl=3600)
def get_identity():
    acc = run_query("SELECT CURRENT_ACCOUNT() AS ACCOUNTNAME")
    usr = run_query("SELECT CURRENT_USER() AS USERNAME")
    return acc["ACCOUNTNAME"][0], usr["USERNAME"][0]

def sanitize_ident(s: str) -> str:
    """è­˜åˆ¥å­ã‚µãƒ‹ã‚¿ã‚¤ã‚ºï¼ˆè‹±æ•°ï¼‹ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®ã¿ï¼‰"""
    return re.sub(r"[^A-Za-z0-9_]", "", s or "")

# -------------------------------------------------
# SHOW éä¾å­˜ã®ãƒ­ãƒ¼ãƒ«ï¼æ¨©é™è§£æ±ºï¼ˆInformation Schemaï¼‰
# -------------------------------------------------
@st.cache_data(ttl=300)
def get_enabled_roles(target_db: str = "TEST_DB") -> list[str]:
    """
    ç¾ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§æœ‰åŠ¹ï¼ˆç¶™æ‰¿å«ã‚€ï¼‰ãªãƒ­ãƒ¼ãƒ«ã€‚
    ENABLED_ROLES ã¯å„DBã® INFORMATION_SCHEMA ã«ã‚ã‚‹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ¬ãƒ™ãƒ«ãƒ“ãƒ¥ãƒ¼ã€‚
    """
    target_db = sanitize_ident(target_db)
    df = run_query(f"SELECT ROLE_NAME FROM {target_db}.INFORMATION_SCHEMA.ENABLED_ROLES")
    return df["ROLE_NAME"].tolist() if not df.empty else []

@st.cache_data(ttl=300)
def get_effective_select_objects(
    target_db: str,
    target_schema: str,
    include_views: bool = True,
    include_materialized_views: bool = False
) -> list[str]:
    """
    Information Schemaã®ã¿ã§åˆ¤å®šï¼š
      - æœ‰åŠ¹ãƒ­ãƒ¼ãƒ«: ENABLED_ROLES
      - æ¨©é™     : OBJECT_PRIVILEGES (SELECT / OWNERSHIP)
    å¯¾è±¡DB/ã‚¹ã‚­ãƒ¼ãƒå†…ã§ SELECT å¯èƒ½ãª TABLE/VIEWï¼ˆï¼‹ä»»æ„ã§ MATERIALIZED VIEWï¼‰åã‚’è¿”ã™ã€‚
    """
    target_db = sanitize_ident(target_db)
    target_schema = sanitize_ident(target_schema)

    roles = get_enabled_roles(target_db)
    if not roles:
        return []

    obj_types = ["TABLE"]
    if include_views:
        obj_types.append("VIEW")
    if include_materialized_views:
        obj_types.append("MATERIALIZED VIEW")

    obj_types_sql = ", ".join(f"'{t}'" for t in obj_types)
    roles_sql = ", ".join(f"'{r}'" for r in roles)

    q = f"""
        SELECT DISTINCT OBJECT_NAME
        FROM {target_db}.INFORMATION_SCHEMA.OBJECT_PRIVILEGES
        WHERE OBJECT_SCHEMA = '{target_schema}'
          AND OBJECT_TYPE IN ({obj_types_sql})
          AND PRIVILEGE_TYPE IN ('SELECT','OWNERSHIP')
          AND GRANTEE IN ({roles_sql})
        ORDER BY OBJECT_NAME
    """
    df = run_query(q)
    return df["OBJECT_NAME"].tolist() if not df.empty else []

@st.cache_data(ttl=300)
def get_allowed_tables() -> list[str]:
    """
    æ¨©é™ãƒ™ãƒ¼ã‚¹ã§å‚ç…§å¯èƒ½ãª TABLE/VIEW ã®ä¸€è¦§ã€‚
    å°†æ¥ TARGETS ã«è¤‡æ•°ã‚¹ã‚­ãƒ¼ãƒã‚’ä¸¦ã¹ãŸå ´åˆã¯å’Œé›†åˆã‚’è¿”ã™ã€‚
    """
    all_effective = set()
    for t in TARGETS:
        objs = get_effective_select_objects(
            target_db=t["db"], target_schema=t["schema"],
            include_views=True, include_materialized_views=False
        )
        all_effective.update(objs)
    return sorted(list(all_effective))

@st.cache_data(ttl=300)
def get_columns_for_table(target_db: str, target_schema: str, table_name: str) -> list[dict]:
    """æŒ‡å®šã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ æƒ…å ±ï¼ˆåå‰ã€å‹ï¼‰ã‚’å–å¾—"""
    tname = sanitize_ident(table_name)
    target_db = sanitize_ident(target_db)
    target_schema = sanitize_ident(target_schema)
    if not tname:
        return []
    
    df_columns = run_query(f"""
        SELECT COLUMN_NAME, DATA_TYPE
        FROM {target_db}.INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA='{target_schema}' AND TABLE_NAME='{tname}'
        ORDER BY ORDINAL_POSITION
    """)
    # è¾æ›¸ã®ãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™
    return df_columns.to_dict('records')


# -------------------------------------------------
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ / ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
# -------------------------------------------------
def to_excel_bytes(df: pd.DataFrame) -> bytes:
    output = BytesIO()
    df_to_save = df.copy()
    for col in df_to_save.select_dtypes(include=['datetimetz']).columns:
        df_to_save[col] = df_to_save[col].dt.tz_localize(None)
    try:
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            df_to_save.to_excel(writer, index=False, sheet_name="ãƒ‡ãƒ¼ã‚¿")
    except Exception:
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df_to_save.to_excel(writer, index=False, sheet_name="ãƒ‡ãƒ¼ã‚¿")
    return output.getvalue()

def generate_download(df: pd.DataFrame, filetype: str = "csv", quote_option='"', split_limit: int = CSV_MAX):
    if filetype in ["csv", "tsv"]:
        sep = "\t" if filetype == "tsv" else ","
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
            for i, start in enumerate(range(0, len(df), split_limit)):
                part = df.iloc[start:start + split_limit].copy()
                output = io.StringIO()
                if quote_option == 'ãªã—':
                    part.to_csv(output, index=False, sep=sep, quoting=csv.QUOTE_NONE, escapechar='\\')
                else:
                    part.to_csv(output, index=False, sep=sep, quotechar=quote_option, quoting=csv.QUOTE_ALL)
                filename = f"part{i + 1}.{filetype}"
                zf.writestr(filename, output.getvalue().encode("utf-8"))
        zip_buffer.seek(0)
        return zip_buffer
    elif filetype == "excel":
        if len(df) > EXCEL_MAX:
            return None
        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            df.to_excel(writer, index=False, sheet_name="Sheet1")
        return output.getvalue()

def stream_query_to_zip(sql: str, sep: str = ",", quotechar: str = '"', split_limit: int = CSV_MAX) -> io.BytesIO:
    """
    Snowflake -> fetchmany -> é€æ¬¡CSVæ›¸ãå‡ºã— -> ZIPï¼ˆåˆ†å‰²ï¼‰
    DataFrameã‚’çµŒç”±ã—ãªã„ãŸã‚é«˜é€Ÿãƒ»çœãƒ¡ãƒ¢ãƒª
    """
    buf = io.BytesIO()
    with zipfile.ZipFile(buf, "w", zipfile.ZIP_DEFLATED) as zf:
        with get_conn().cursor() as cur:
            cur.execute(sql)
            cols = [c[0] for c in cur.description]
            part_no, written = 1, 0
            out = io.StringIO()
            writer = csv.writer(out, delimiter=sep, quotechar=quotechar, quoting=csv.QUOTE_ALL)
            writer.writerow(cols)
            while True:
                rows = cur.fetchmany(10_000)  # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯èª¿æ•´å¯
                if not rows:
                    break
                for row in rows:
                    if written and written % split_limit == 0:
                        zf.writestr(f"part{part_no}.csv", out.getvalue().encode("utf-8"))
                        part_no += 1
                        out = io.StringIO()
                        writer = csv.writer(out, delimiter=sep, quotechar=quotechar, quoting=csv.QUOTE_ALL)
                        writer.writerow(cols)
                    writer.writerow(row)
                    written += 1
            if written == 0:
                zf.writestr("part1.csv", out.getvalue().encode("utf-8"))
            elif out.tell() > 0: # æœ€å¾Œã®ãƒãƒƒãƒã‚’æ›¸ãè¾¼ã‚€
                zf.writestr(f"part{part_no}.csv", out.getvalue().encode("utf-8"))
    buf.seek(0)
    return buf

def show_download_ui(df: pd.DataFrame, file_name_prefix: str, key_prefix: str = "download"):
    """ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰UIï¼ˆDataFrameæº–å‚™æ¸ˆã¿ç”¨ï¼‰"""
    if df.empty:
        st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    today_str = datetime.date.today().strftime("%Y%m%d")
    col1, col2, col3 = st.columns([1, 1, 2])
    with col1:
        quote_option = st.selectbox("å›²ã„æ–‡å­—", ['"', "'", 'ãªã—'], index=0, key=f"{key_prefix}_quote")
    with col2:
        ft = st.selectbox("å½¢å¼", ["csv", "tsv", "excel"], index=0, key=f"{key_prefix}_fmt")
    with col3:
        st.write("") # ãƒœã‚¿ãƒ³ã‚’ä¸­å¤®æƒãˆã«ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼
        st.write("")
        if ft in ("csv","tsv"):
            data = generate_download(df, filetype=ft, quote_option=quote_option)
            st.download_button(
                label="ğŸ“¥ ZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=data,
                file_name=f"{file_name_prefix}_{today_str}_{ft.upper()}.zip",
                mime="application/zip",
                key=f"{key_prefix}_dlzip"
            )
        else:
            data = generate_download(df, filetype="excel")
            if data:
                st.download_button(
                    label="ğŸ“¥ Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=data,
                    file_name=f"{file_name_prefix}_{today_str}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    key=f"{key_prefix}_xldl"
                )
            else:
                st.warning(f"Excelã¯{EXCEL_MAX}ä»¶ã‚’è¶…ãˆã‚‹ãŸã‚ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã€‚")

def download_ready_ui(df_preview: pd.DataFrame, table_name: str, sql_all_func, sql_query: str):
    """
    å¾“æ¥ã®ã€Œå…¨ä»¶ã‚’DFã«ç©ã‚“ã§ã‹ã‚‰DLã€ï¼‹ é«˜é€Ÿã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°DLï¼ˆDFä¸è¦ï¼‰ã®ä¸¡å¯¾å¿œã€‚
    ï¼ˆS3æ©Ÿèƒ½ã¯å‰Šé™¤ï¼‰
    """
    if df_preview.empty:
        st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
        
    st.markdown("**ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")
    colA, colB = st.columns(2)
    
    with colA:
        st.caption("A: å…¨ä»¶å–å¾—ã—ã¦ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        if st.button("ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™ï¼ˆå…¨ä»¶å–å¾—ï¼‰"):
            with st.spinner("å…¨ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                st.session_state.builder_df_for_download = sql_all_func()
            st.success(f"å…¨ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ ({len(st.session_state.builder_df_for_download)}ä»¶)")
        
        # å…¨ä»¶DFãŒæº–å‚™ã§ããŸã‚‰DLãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        if not st.session_state.builder_df_for_download.empty:
            show_download_ui(
                st.session_state.builder_df_for_download,
                file_name_prefix=table_name,
                key_prefix="builder_dl_full"
            )

    with colB:
        st.caption("B: é«˜é€Ÿã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼ˆå¤§å®¹é‡å‘ã‘ï¼‰")
        sep_choice = st.radio("åŒºåˆ‡ã‚Š", ["CSV", "TSV"], horizontal=True, key="fast_sep")
        sep = "\t" if sep_choice == "TSV" else ","
        quote_option = st.selectbox("å›²ã„æ–‡å­—", ['"', "'"], index=0, key="fast_quote")
        
        if st.button("ğŸ“¥ é«˜é€ŸZIPãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰"):
            if not sql_query:
                st.error("å®Ÿè¡Œå¯¾è±¡ã®SQLãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

            with st.spinner("ZIPç”Ÿæˆä¸­..."):
                data = stream_query_to_zip(sql_query, sep=sep, quotechar=quote_option)
            
            st.download_button(
                "ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹",
                data=data,
                file_name=f"{table_name}_{datetime.date.today():%Y%m%d}_server.zip",
                mime="application/zip",
                key="fast_zip_dl"
            )

# -------------------------------------------------
# SQLæ•´å½¢
# -------------------------------------------------
_LIMIT_PATTERN = re.compile(r"(?i)LIMIT\s+\d+")

def remove_limit(sql: str) -> str:
    return _LIMIT_PATTERN.sub("", sql).strip()

def clean_sql(sql: str) -> str:
    if not sql:
        return ""
    return sql.strip().rstrip(";")

def get_full_data_builder() -> pd.DataFrame:
    """SQLãƒ“ãƒ«ãƒ€ãƒ¼ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å…¨ä»¶å–å¾—"""
    sql = st.session_state.get("builder_sql", "")
    if not sql:
        st.warning("å®Ÿè¡Œå¯¾è±¡ã®SQLãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return pd.DataFrame()
    sql_full = clean_sql(remove_limit(sql))
    return run_query(sql_full)

# -------------------------------------------------
# ç”»é¢ä¸Šéƒ¨ï¼šãƒ˜ãƒƒãƒ€ / ã‚³ãƒãƒ³ãƒ‰ãƒãƒ¼ / ã‚¿ãƒ–
# -------------------------------------------------
current_account, current_user = get_identity()

st.markdown(f"### ğŸ“Š ãƒ‡ãƒ¼ã‚¿é–²è¦§ & ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
st.markdown(
    f"<span class='small-muted'>ã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: <b>{current_account}</b> / ãƒ¦ãƒ¼ã‚¶ãƒ¼: <b>{current_user}</b></span>",
    unsafe_allow_html=True
)

# ã‚³ãƒãƒ³ãƒ‰ãƒãƒ¼ï¼ˆDB/ã‚¹ã‚­ãƒ¼ãƒã¯å½“é¢å›ºå®šï¼‰
target_db = sanitize_ident(TARGETS[0]["db"])
target_schema = sanitize_ident(TARGETS[0]["schema"])

# æ¨©é™ãƒ™ãƒ¼ã‚¹ã®å€™è£œä¸€è¦§
all_tables = get_allowed_tables()

# ã‚³ãƒãƒ³ãƒ‰ãƒãƒ¼ã¯å¯¾è±¡è¡¨ç¤ºã®ã¿ã«ç°¡ç´ åŒ–
st.markdown(f"**å¯¾è±¡**: `{target_db}.{target_schema}`")

st.markdown("<hr/>", unsafe_allow_html=True)
tabs = st.tabs(["â‘  SQLãƒ“ãƒ«ãƒ€ãƒ¼ (ãƒ•ã‚£ãƒ«ã‚¿ & çµåˆ)", "â‘¡ ãƒ¡ã‚¿æƒ…å ±"])


# -------------------------------------------------
# â‘  SQLãƒ“ãƒ«ãƒ€ãƒ¼ ã‚¿ãƒ–
# -------------------------------------------------
with tabs[0]:
    st.subheader("SQLãƒ“ãƒ«ãƒ€ãƒ¼")
    
    # -----------------
    # Step 1: ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾© (FROM / JOIN)
    # -----------------
    st.markdown("#### Step 1: ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾© (FROM / JOIN)")
    
    # ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
    base_table_options = [""] + all_tables
    try:
        base_table_index = base_table_options.index(st.session_state.builder_base_table)
    except ValueError:
        base_table_index = 0
        
    base_table = st.selectbox(
        "ä¸»ãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ“ãƒ¥ãƒ¼",
        base_table_options,
        index=base_table_index,
        key="builder_base_table_select" # st.session_state.builder_base_table ã¨é€£å‹•ã•ã›ã‚‹
    )
    if base_table != st.session_state.builder_base_table:
        st.session_state.builder_base_table = base_table
        st.session_state.builder_join_steps = [] # ãƒ™ãƒ¼ã‚¹å¤‰æ›´ã§ãƒªã‚»ãƒƒãƒˆ
        st.session_state.builder_available_columns = []
        st.rerun()

    # çµåˆã‚¹ãƒ†ãƒƒãƒ—
    c_add, c_clear = st.columns(2)
    with c_add:
        if st.button("ï¼‹ çµåˆã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ "):
            st.session_state.builder_join_steps.append({
                "right_table": "",
                "left_key": [],
                "right_key": [],
                "how": "INNER"
            })
    with c_clear:
        if st.button("ğŸ§¹ çµåˆã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¯ãƒªã‚¢"):
            st.session_state.builder_join_steps = []
            st.rerun()

    # çµåˆã‚¹ãƒ†ãƒƒãƒ—UI
    remove_index = None
    all_join_tables_valid = True
    
    # ã‚«ãƒ©ãƒ å–å¾—é–¢æ•°ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ´»ç”¨ï¼‰
    @st.cache_data(ttl=300)
    def get_cols(tbl_name):
        if not tbl_name: return []
        cols_data = get_columns_for_table(target_db, target_schema, tbl_name)
        return [c["COLUMN_NAME"] for c in cols_data]

    current_left_table = st.session_state.builder_base_table
    
    for i, step in enumerate(st.session_state.builder_join_steps):
        with st.container(border=True):
            # (ä¿®æ­£) ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã«ã‚¿ã‚¤ãƒˆãƒ«ã¨å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’é…ç½®
            col_title, col_del_btn = st.columns([1, 0.1])
            with col_title:
                st.markdown(f"**Join Step {i+1}**")
            with col_del_btn:
                if st.button("âœ•", key=f"rm_{i}", help="ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å‰Šé™¤"):
                    remove_index = i

            left_cols = get_cols(current_left_table)
            options = [""] + [t for t in all_tables if t != current_left_table] if current_left_table else [""] + all_tables
            
            try:
                rt_index = options.index(step.get("right_table",""))
            except ValueError:
                rt_index = 0
            
            step["right_table"] = st.selectbox(
                f"çµåˆå…ˆãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ“ãƒ¥ãƒ¼ (Step {i+1})", options,
                index=rt_index,
                key=f"rt_{i}"
            )
            step["how"] = st.selectbox(
                "çµåˆæ–¹æ³•", ["INNER","LEFT","RIGHT","FULL"],
                index=["INNER","LEFT","RIGHT","FULL"].index(step.get("how","INNER")),
                key=f"how_{i}"
            )

            right_cols = get_cols(step["right_table"])
            
            # (ä¿®æ­£) å‰Šé™¤ãƒœã‚¿ãƒ³ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã«ç§»å‹•ã—ãŸãŸã‚ã€ã‚­ãƒ¼å…¥åŠ›ã‚¨ãƒªã‚¢ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå¤‰æ›´
            c1, c2 = st.columns(2) 
            with c1:
                step["left_key"] = st.multiselect(f"å·¦ã‚­ãƒ¼ï¼ˆ{current_left_table or 'æœªé¸æŠ'}ï¼‰", left_cols, default=step.get("left_key", []), key=f"lk_{i}")
            with c2:
                step["right_key"] = st.multiselect(f"å³ã‚­ãƒ¼ï¼ˆ{step['right_table'] or 'æœªé¸æŠ'}ï¼‰", right_cols, default=step.get("right_key", []), key=f"rk_{i}")

            if step["left_key"] and step["right_key"] and len(step["left_key"]) != len(step["right_key"]):
                st.warning("âš  å·¦å³ã®ã‚­ãƒ¼æ•°ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")
            
            if not step["right_table"] or not step["left_key"] or not step["right_key"]:
                all_join_tables_valid = False

            current_left_table = step["right_table"] # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã®å·¦å´ã¯ã€ä»Šã®ã‚¹ãƒ†ãƒƒãƒ—ã®å³å´

    if remove_index is not None:
        st.session_state.builder_join_steps.pop(remove_index)
        st.rerun()

    # -----------------
    # Step 2: æ¡ä»¶æŒ‡å®š (WHERE / SELECT)
    # -----------------
    st.markdown("#### Step 2: æ¡ä»¶æŒ‡å®š (WHERE / SELECT)")

    # Step 1 ã®å®šç¾©ã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ ä¸€è¦§ã‚’ç”Ÿæˆ
    if st.button("ãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©ã‚’ç¢ºå®šï¼ˆStep 2 ã®ã‚«ãƒ©ãƒ ã‚’æ›´æ–°ï¼‰"):
        st.session_state.builder_available_columns = []
        st.session_state.builder_where_conditions = [] # å‹•çš„UIç”¨ãƒªã‚»ãƒƒãƒˆ
        st.session_state.builder_where_next_id = 0 # å‹•çš„UIç”¨ãƒªã‚»ãƒƒãƒˆ
        st.session_state.builder_selected_columns = []
        
        tables_in_use = {} # é‡è¤‡ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¨ã‚¤ãƒªã‚¢ã‚¹ã‚’ä»˜ä¸
        
        def add_cols(tbl_name, alias):
            cols_data = get_columns_for_table(target_db, target_schema, tbl_name)
            for c in cols_data:
                st.session_state.builder_available_columns.append({
                    "fq_name": f"{alias}.{c['COLUMN_NAME']}",
                    "table_alias": alias,
                    "table_name": tbl_name,
                    "column": c['COLUMN_NAME'],
                    "dtype": c['DATA_TYPE'].upper()
                })

        if st.session_state.builder_base_table:
            base_alias = sanitize_ident(st.session_state.builder_base_table)
            tables_in_use[base_alias] = 1
            add_cols(st.session_state.builder_base_table, base_alias)

        for step in st.session_state.builder_join_steps:
            if step["right_table"]:
                alias = sanitize_ident(step["right_table"])
                if alias in tables_in_use:
                    tables_in_use[alias] += 1
                    alias = f"{alias}_{tables_in_use[alias]}" # TBL_2
                else:
                    tables_in_use[alias] = 1
                add_cols(step["right_table"], alias)
        
        st.success(f"{len(st.session_state.builder_available_columns)} ä»¶ã®ã‚«ãƒ©ãƒ ã‚’èª­è¾¼ã¿ã¾ã—ãŸã€‚")

    if st.session_state.builder_available_columns:
        
        # --- ãƒ•ã‚£ãƒ«ã‚¿ (WHERE) ---
        # st.form ã®å¤–ã§å‹•çš„ã«ç®¡ç†
        with st.expander("ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ (WHERE)", expanded=True):
            all_cols_fq_names = [c["fq_name"] for c in st.session_state.builder_available_columns]
            
            # æ¡ä»¶è¿½åŠ ãƒœã‚¿ãƒ³
            if st.button("ï¼‹ ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ã‚’è¿½åŠ "):
                new_id = st.session_state.builder_where_next_id
                st.session_state.builder_where_conditions.append({
                    "id": new_id,
                    "column": all_cols_fq_names[0] if all_cols_fq_names else "",
                    "operator": "LIKE",
                    "value": ""
                })
                st.session_state.builder_where_next_id += 1
                st.rerun()

            # æ—¢å­˜ã®æ¡ä»¶ã‚’ãƒ«ãƒ¼ãƒ—è¡¨ç¤º
            indices_to_remove = []
            for i, condition in enumerate(st.session_state.builder_where_conditions):
                # ãƒ¦ãƒ‹ãƒ¼ã‚¯ã‚­ãƒ¼ã®ãŸã‚ id ã‚’ä½¿ç”¨
                condition_id = condition["id"]
                
                # (ä¿®æ­£) ãƒ•ã‚©ãƒ¼ãƒ ã‚’æ¨ªä¸¦ã³ã«
                c1, c2, c3, c4 = st.columns([3, 2, 3, 1])
                
                # 1. ã‚«ãƒ©ãƒ é¸æŠ
                with c1:
                    try:
                        col_index = all_cols_fq_names.index(condition["column"])
                    except ValueError:
                        col_index = 0
                    condition["column"] = st.selectbox(
                        "ã‚«ãƒ©ãƒ ",
                        all_cols_fq_names, 
                        index=col_index, 
                        key=f"where_col_{condition_id}",
                        label_visibility="collapsed"
                    )
                
                # 2. æ¼”ç®—å­é¸æŠ
                with c2:
                    operators = ["LIKE", "=", "!=", ">", ">=", "<", "<=", "IS NULL", "IS NOT NULL"]
                    try:
                        op_index = operators.index(condition["operator"])
                    except ValueError:
                        op_index = 0
                    condition["operator"] = st.selectbox(
                        "æ¼”ç®—å­",
                        operators, 
                        index=op_index, 
                        key=f"where_op_{condition_id}",
                        label_visibility="collapsed"
                    )

                # 3. å€¤å…¥åŠ›
                is_null_op = condition["operator"] in ["IS NULL", "IS NOT NULL"]
                with c3:
                    condition["value"] = st.text_input(
                        "å€¤",
                        value=condition["value"], 
                        key=f"where_val_{condition_id}",
                        disabled=is_null_op,
                        placeholder="å€¤ (IS NULL/NOT NULL ã¯ç©ºæ¬„)",
                        label_visibility="collapsed"
                    )

                # 4. å‰Šé™¤ãƒœã‚¿ãƒ³
                with c4:
                    if st.button("å‰Šé™¤", key=f"where_del_{condition_id}"):
                        indices_to_remove.append(i)


            # å‰Šé™¤å‡¦ç†ï¼ˆãƒ«ãƒ¼ãƒ—ã®å¤–ã§å®Ÿè¡Œï¼‰
            if indices_to_remove:
                # å¾Œã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‹ã‚‰å‰Šé™¤ã™ã‚‹
                for index in sorted(indices_to_remove, reverse=True):
                    st.session_state.builder_where_conditions.pop(index)
                st.rerun()


        # --- ãƒ•ã‚©ãƒ¼ãƒ  (SELECT ã¨ å®Ÿè¡Œ) ---
        with st.form(key="select_form", clear_on_submit=False):
            
            # --- è¡¨ç¤ºã‚«ãƒ©ãƒ  (SELECT) ---
            # (ä¿®æ­£) st.expander ã§å›²ã‚€
            with st.expander("è¡¨ç¤ºã‚«ãƒ©ãƒ  (SELECT)", expanded=True):
                default_cols = st.session_state.builder_selected_columns or [c["fq_name"] for c in st.session_state.builder_available_columns]
                selected_columns = st.multiselect(
                    "è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ", 
                    [c["fq_name"] for c in st.session_state.builder_available_columns], 
                    default=default_cols,
                    key="builder_select_multiselect",
                    label_visibility="collapsed" # ãƒ©ãƒ™ãƒ«ã‚’éè¡¨ç¤º
                )
                st.session_state.builder_selected_columns = selected_columns

            # --- å®Ÿè¡Œ ---
            submitted = st.form_submit_button("é©ç”¨ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼100ä»¶ï¼‰", type="primary")
            if submitted:
                # SQLã‚’æ§‹ç¯‰
                try:
                    # SELECTå¥
                    if not st.session_state.builder_selected_columns:
                        st.error("è¡¨ç¤ºã‚«ãƒ©ãƒ ã‚’1ã¤ä»¥ä¸Šé¸æŠã—ã¦ãã ã•ã„ã€‚")
                    else:
                        select_cols = [f'"{c["table_alias"]}"."{c["column"]}" AS "{c["fq_name"]}"' 
                                       for c in st.session_state.builder_available_columns 
                                       if c["fq_name"] in st.session_state.builder_selected_columns]
                        select_sql = f"SELECT {', '.join(select_cols)}"

                        # FROM / JOINå¥
                        from_sql = ""
                        tables_in_use = {} # ã‚¨ã‚¤ãƒªã‚¢ã‚¹ç®¡ç†
                        fq_db_schema = f"{target_db}.{target_schema}"

                        def get_alias(tbl_name):
                            alias = sanitize_ident(tbl_name)
                            if alias in tables_in_use:
                                tables_in_use[alias] += 1
                                alias = f"{alias}_{tables_in_use[alias]}"
                            else:
                                tables_in_use[alias] = 1
                            return alias

                        base_table = st.session_state.builder_base_table
                        if not base_table:
                            raise ValueError("ä¸»ãƒ†ãƒ¼ãƒ–ãƒ«ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
                        
                        base_alias = get_alias(base_table)
                        from_sql = f'FROM {fq_db_schema}."{base_table}" AS "{base_alias}"'
                        
                        current_left_alias = base_alias

                        for step in st.session_state.builder_join_steps:
                            if not (step["right_table"] and step["left_key"] and step["right_key"] and len(step["left_key"]) == len(step["right_key"])):
                                raise ValueError("çµåˆã‚¹ãƒ†ãƒƒãƒ—ã®è¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚")
                            
                            right_alias = get_alias(step["right_table"])
                            how = step["how"]
                            
                            on_clauses = []
                            for lk, rk in zip(step["left_key"], step["right_key"]):
                                on_clauses.append(f'"{current_left_alias}"."{lk}" = "{right_alias}"."{rk}"')
                            on_sql = " AND ".join(on_clauses)
                            
                            from_sql += f' {how} JOIN {fq_db_schema}."{step["right_table"]}" AS "{right_alias}" ON {on_sql}'
                            
                            current_left_alias = right_alias # é€£çµ

                        # WHEREå¥
                        where_clauses = []
                        
                        # (å¤‰æ›´) builder_where_conditions ã‹ã‚‰æ§‹ç¯‰
                        for condition in st.session_state.builder_where_conditions:
                            col_fq_name = condition["column"]
                            operator = condition["operator"]
                            value = condition["value"]

                            col_info = next((c for c in st.session_state.builder_available_columns if c["fq_name"] == col_fq_name), None)
                            if not col_info: continue
                            
                            col_sql = f'"{col_info["table_alias"]}"."{col_info["column"]}"'
                            col_dtype = col_info["dtype"]

                            # IS NULL / IS NOT NULL
                            if operator in ["IS NULL", "IS NOT NULL"]:
                                where_clauses.append(f"{col_sql} {operator}")
                                continue

                            # å€¤ãŒç©ºã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                            if not value:
                                continue

                            # æ¼”ç®—å­ã¨å‹ã«å¿œã˜ã¦å¥ã‚’æ§‹ç¯‰
                            if operator == "LIKE":
                                where_clauses.append(f"{col_sql} LIKE '%{value}%'")
                            else:
                                # æ•°å€¤å‹ã‹ï¼Ÿ
                                is_numeric_type = any(t in col_dtype for t in ["NUMBER", "INT", "FLOAT", "DECIMAL", "DOUBLE"])
                                if is_numeric_type:
                                    # å€¤ãŒæ•°å€¤ã¨ã—ã¦å¦¥å½“ã‹ï¼ˆç°¡æ˜“ãƒã‚§ãƒƒã‚¯ï¼‰
                                    if re.fullmatch(r"-?\d+(\.\d+)?", value):
                                        where_clauses.append(f"{col_sql} {operator} {value}")
                                    else:
                                        st.warning(f"è­¦å‘Š: ã‚«ãƒ©ãƒ  {col_fq_name} ã®å€¤ '{value}' ã¯æ•°å€¤ã¨ã—ã¦ç„¡åŠ¹ãªãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸã€‚")
                                else:
                                    # æ–‡å­—åˆ—ãƒ»æ—¥ä»˜ãƒ»æ™‚åˆ»å‹ã¯ ' ã§å›²ã‚€
                                    # (æ³¨: Snowflakeã¯æ—¥ä»˜ã‚„æ™‚åˆ»ã‚‚ ' ã§å›²ã‚€)
                                    value_escaped = value.replace("'", "''") # ã‚·ãƒ³ã‚°ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
                                    where_clauses.append(f"{col_sql} {operator} '{value_escaped}'")
                        
                        where_sql = f"WHERE {' AND '.join(where_clauses)}" if where_clauses else ""
                        
                        # SQLçµåˆ
                        final_sql = f"{select_sql} {from_sql} {where_sql}"
                        st.session_state.builder_sql = final_sql
                        
                        # å®Ÿè¡Œ
                        df_preview = run_query(final_sql + " LIMIT 100")
                        st.session_state.builder_df_preview = df_preview
                        st.session_state.builder_df_for_download = pd.DataFrame() # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œã§ãƒªã‚»ãƒƒãƒˆ
                        st.success(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ {len(df_preview)} ä»¶ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")

                except Exception as e:
                    st.error(f"SQLã®æ§‹ç¯‰ã¾ãŸã¯å®Ÿè¡Œã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    st.session_state.builder_sql = ""
                    st.session_state.builder_df_preview = pd.DataFrame()

    # -----------------
    # Step 3: çµæœè¡¨ç¤º
    # -----------------
    st.markdown("#### Step 3: çµæœè¡¨ç¤º")
    
    if st.session_state.builder_sql:
        st.markdown("**å®Ÿè¡Œã•ã‚ŒãŸSQLï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨ï¼‰**")
        st.code(st.session_state.builder_sql + " LIMIT 100", language="sql")
    
    if not st.session_state.builder_df_preview.empty:
        st.dataframe(st.session_state.builder_df_preview.head(50), use_container_width=True)

        # ä»¶æ•°ãƒã‚§ãƒƒã‚¯
        with st.container():
            show_count = st.checkbox("ä»¶æ•°ã‚’è¨ˆç®—ã™ã‚‹ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¾Œï¼‰", value=False)
            if show_count:
                if st.session_state.builder_sql:
                    # SELECT ... FROM ... -> SELECT COUNT(*) FROM ...
                    from_where = st.session_state.builder_sql.split("FROM", 1)[1]
                    cnt_sql = "SELECT COUNT(*) AS cnt FROM " + from_where
                    try:
                        total = run_query(cnt_sql).iloc[0, 0]
                        st.markdown(f"<span class='badge badge-run'>ä»¶æ•°: {total} ä»¶</span>", unsafe_allow_html=True)
                    except Exception as e:
                        st.warning("ä»¶æ•°è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        st.write(e)
                else:
                    st.warning("ä»¶æ•°è¨ˆç®—ã®å…ƒã¨ãªã‚‹SQLãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™
        download_ready_ui(
            df_preview=st.session_state.builder_df_preview,
            table_name=st.session_state.builder_base_table or "query",
            sql_all_func=get_full_data_builder,
            sql_query=st.session_state.builder_sql
        )
    
    elif st.session_state.builder_available_columns:
        st.info("ä¸Šè¨˜ãƒ•ã‚©ãƒ¼ãƒ ã§æ¡ä»¶ã‚’æŒ‡å®šã—ã€ã€Œé©ç”¨ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼100ä»¶ï¼‰ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.info("Step 1 ã§ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å®šç¾©ã—ã€ã€ŒStep 2 ã®ã‚«ãƒ©ãƒ ã‚’æ›´æ–°ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")


# -------------------------------------------------
# â‘¡ ãƒ¡ã‚¿æƒ…å ± ã‚¿ãƒ–
# -------------------------------------------------
with tabs[1]:
    st.subheader("ãƒ¡ã‚¿æƒ…å ±")
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’é¸æŠã•ã›ã‚‹
    selected_table_meta = st.selectbox(
        "ãƒ¡ã‚¿æƒ…å ±ã‚’è¡¨ç¤ºã™ã‚‹ãƒ†ãƒ¼ãƒ–ãƒ«/ãƒ“ãƒ¥ãƒ¼ã‚’é¸æŠ", 
        all_tables, 
        index=0 if all_tables else None, 
        placeholder="é¸æŠã—ã¦ãã ã•ã„",
        key="meta_table_select"
    )

    if not selected_table_meta:
        st.info("ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ãƒ“ãƒ¥ãƒ¼ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
    else:
        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‚³ãƒ¡ãƒ³ãƒˆ
        df_comment = run_query(f"""
            SELECT COMMENT
            FROM {target_db}.INFORMATION_SCHEMA.TABLES
            WHERE TABLE_SCHEMA='{target_schema}' AND TABLE_NAME='{sanitize_ident(selected_table_meta)}'
        """)
        comment = df_comment.iloc[0,0] if (not df_comment.empty and df_comment.iloc[0,0]) else "(èª¬æ˜ãªã—)"
        st.markdown(f"**ãƒ†ãƒ¼ãƒ–ãƒ«èª¬æ˜:** {comment}")

        # ã‚«ãƒ©ãƒ è¾æ›¸ï¼ˆCODE_Mï¼‰
        st.markdown("**ã‚«ãƒ©ãƒ è¾æ›¸ï¼ˆCODE_Mï¼‰ã‚µãƒ³ãƒ—ãƒ«**")
        
        # ã‚«ãƒ©ãƒ ä¸€è¦§å–å¾—
        cols_data = get_columns_for_table(target_db, target_schema, selected_table_meta)
        
        if not cols_data:
            st.warning("ã“ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚«ãƒ©ãƒ æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            # ã‚«ãƒ©ãƒ ä¸€è¦§ã‚’DataFrameã§è¡¨ç¤º
            st.markdown(f"**{selected_table_meta} ã®ã‚«ãƒ©ãƒ ä¸€è¦§**")
            st.dataframe(pd.DataFrame(cols_data), use_container_width=True)

            # CODE_Mæ¤œç´¢
            cols_list_for_sql = "', '".join([c['COLUMN_NAME'] for c in cols_data])
            code_df = run_query(f"""
SELECT "ã‚«ãƒ©ãƒ å", "ã‚³ãƒ¼ãƒ‰å€¤", "ã‚³ãƒ¼ãƒ‰å€¤åç§°"
FROM {target_db}.{target_schema}.CODE_M
WHERE "ã‚«ãƒ©ãƒ å" IN ('{cols_list_for_sql}')
""")
            if code_df.empty:
                st.caption("CODE_M ã«å¯¾å¿œã‚¨ãƒ³ãƒˆãƒªã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.dataframe(code_df.head(200), use_container_width=True)
