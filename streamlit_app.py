import streamlit as st
import pandas as pd
import boto3
import io
import os
import csv 
from datetime import datetime
from botocore.exceptions import NoCredentialsError, PartialCredentialsError
import re

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="SQL to S3 Uploader", layout="wide")
st.title("SQLã‚¯ã‚¨ãƒªå®Ÿè¡Œ & S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ğŸ“¤ (Snowflake)")
st.markdown("""
SQLã‚’å®Ÿè¡Œã—ã€ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç¢ºèªã—ã¦ã‹ã‚‰S3ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
ï¼ˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã¯Snowflakeã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«å¿œã˜ã¦è‡ªå‹•çš„ã«æ±ºå®šã•ã‚Œã¾ã™ï¼‰
""")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
if 'step' not in st.session_state:
    st.session_state.step = 1
if 'sql_query' not in st.session_state:
    st.session_state.sql_query = ""
if 'preview_df' not in st.session_state:
    st.session_state.preview_df = pd.DataFrame()
if 'preview_count' not in st.session_state:
    st.session_state.preview_count = 0
if 'has_more_than_100' not in st.session_state:
    st.session_state.has_more_than_100 = False

# =============================================================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° (å¤‰æ›´ãªã—)
# =============================================================================
def get_snowflake_account(conn):
    try:
        account_df = conn.query("SELECT CURRENT_ACCOUNT()", ttl=0)
        snowflake_account = account_df.iloc[0, 0]
        st.info(f"Snowflakeã‚¢ã‚«ã‚¦ãƒ³ãƒˆ: `{snowflake_account}` ã¨ã—ã¦èªè­˜ã—ã¦ã„ã¾ã™ã€‚")
        return snowflake_account
    except Exception as e:
        st.error(f"Snowflakeã‚¢ã‚«ã‚¦ãƒ³ãƒˆåã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def get_s3_destination(snowflake_account):
    if not snowflake_account: return None, None
    # --- â–¼â–¼â–¼ ã“ã“ã§ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã”ã¨ã®åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¨­å®š â–¼â–¼â–¼ ---
    if snowflake_account == "ACCOUNT_A":
        bucket = "my-admin-bucket"
        key_prefix = "reports/account_a/"
    elif snowflake_account == "ACCOUNT_B_PROD":
        bucket = "my-data-lake-prod"
        key_prefix = "analysis_results/prod/"
    else:
        bucket = "my-dev-sandbox-bucket"
        key_prefix = f"common_uploads/{snowflake_account.lower()}/"
    # --- â–²â–²â–² åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã®è¨­å®šã¯ã“ã“ã¾ã§ â–²â–²â–² ---
    return bucket, key_prefix

def get_s3_client():
    try:
        s3_client = boto3.client(
            's3',
            aws_access_key_id=st.secrets["s3"]["aws_access_key_id"],
            aws_secret_access_key=st.secrets["s3"]["aws_secret_access_key"],
            region_name=st.secrets["s3"].get("region_name")
        )
        return s3_client
    except (KeyError, NoCredentialsError):
        st.error("S3ã®èªè¨¼æƒ…å ±ãŒSnowflake Secretsã«æ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None
    except Exception as e:
        st.error(f"S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# =============================================================================
# ã‚¹ãƒ†ãƒƒãƒ— 1: SQLã®å…¥åŠ›ã¨ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (å¤‰æ›´ãªã—)
# =============================================================================
def step1_sql_input():
    st.header("1. å®Ÿè¡Œã™ã‚‹SQLã‚¯ã‚¨ãƒª")
    sql_input = st.text_area(
        "SQLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", 
        value=st.session_state.sql_query,
        height=150, 
        placeholder="ä¾‹: SELECT * FROM my_table;"
    )
    
    st.session_state.sql_query = sql_input

    if st.button("æ¬¡ã¸ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤ºï¼‰", type="primary"):
        if not st.session_state.sql_query:
            st.warning("SQLã‚¯ã‚¨ãƒªãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.stop()
        
        try:
            conn = st.connection("snowflake")
            
            base_query = re.sub(r'LIMIT\s+\d+\s*$', '', st.session_state.sql_query, flags=re.IGNORECASE).strip().rstrip(';')
            preview_query = f"{base_query} LIMIT 101"
            
            with st.spinner("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­ã§ã™..."):
                preview_df = conn.query(preview_query)
            
            count = len(preview_df)
            st.session_state.preview_df = preview_df 

            if count == 0:
                st.warning("ã‚¯ã‚¨ãƒªçµæœã¯0ä»¶ã§ã—ãŸã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                st.session_state.preview_count = 0
                st.session_state.has_more_than_100 = False
                st.session_state.preview_df = pd.DataFrame()
            
            elif count <= 100:
                st.success(f"æ¤œè¨¼å®Œäº†: **{count}** ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ï¼ˆå…¨ä»¶ï¼‰")
                st.session_state.preview_count = count
                st.session_state.has_more_than_100 = False
                st.session_state.step = 2
                st.rerun()

            else: # count == 101
                st.success("æ¤œè¨¼å®Œäº†: **100ä»¶ã‚’è¶…ãˆã‚‹ãƒ‡ãƒ¼ã‚¿** ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                st.session_state.preview_count = 101
                st.session_state.has_more_than_100 = True
                st.session_state.step = 2
                st.rerun()

        except Exception as e:
            st.error(f"SQLå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

# =============================================================================
# ã‚¹ãƒ†ãƒƒãƒ— 2: æ›¸å¼è¨­å®šã¨S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ãƒ†ã‚­ã‚¹ãƒˆä¿®æ­£ç‰ˆ)
# =============================================================================
def step2_format_and_upload():
    st.header("1. å®Ÿè¡Œã™ã‚‹SQLã‚¯ã‚¨ãƒªï¼ˆç¢ºèªï¼‰")
    
    # --- â–¼â–¼â–¼ ä¿®æ­£ç‚¹ 1: ä»¶æ•°è¡¨ç¤ºã® st.info(...) ã‚’å‰Šé™¤ â–¼â–¼â–¼ ---
    # (st.info(...) ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‰Šé™¤)
    # --- â–²â–²â–² ä¿®æ­£ç‚¹ 1 â–²â–²â–² ---
        
    st.code(st.session_state.sql_query, language="sql")

    if not st.session_state.preview_df.empty:
        st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        if st.session_state.has_more_than_100:
            st.dataframe(st.session_state.preview_df.head(100))
        else:
            st.dataframe(st.session_state.preview_df)

    
    st.header("2. å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«æ›¸å¼")
    file_format = st.selectbox(
        "ãƒ•ã‚¡ã‚¤ãƒ«æ›¸å¼",
        ("CSV", "Excel", "TSV"),
        index=0
    )

    include_header = True
    quoting = "ALL" 

    if file_format in ("CSV", "TSV"):
        col_opt1, col_opt2 = st.columns(2)
        with col_opt1:
            header_option = st.radio(
                "ãƒ˜ãƒƒãƒ€ãƒ¼", 
                ("ã‚ã‚Š", "ãªã—"), 
                index=0
            )
            include_header = (header_option == "ã‚ã‚Š")

        with col_opt2:
            quote_option = st.radio(
                "ãƒ€ãƒ–ãƒ«ã‚¯ã‚©ãƒ¼ãƒˆ", 
                ("ä»˜ä¸ã™ã‚‹ (æ¨å¥¨)", "ä»˜ä¸ã—ãªã„"), 
                index=0
            )
            quoting = csv.QUOTE_ALL if (quote_option == "ä»˜ä¸ã™ã‚‹ (æ¨å¥¨)") else csv.QUOTE_NONE
    else:
        st.caption("Excelå½¢å¼ã§ã¯ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã¯å¸¸ã«å‡ºåŠ›ã•ã‚Œã€ã‚¯ã‚©ãƒ¼ãƒˆã¯è‡ªå‹•çš„ã«å‡¦ç†ã•ã‚Œã¾ã™ã€‚")


    st.divider()

    col1, col2 = st.columns([1, 1])
    with col1:
        if st.button("æˆ»ã‚‹ï¼ˆSQLã‚’ä¿®æ­£ï¼‰"):
            st.session_state.step = 1
            st.session_state.preview_df = pd.DataFrame() 
            st.rerun()
            
    with col2:
        # --- â–¼â–¼â–¼ ä¿®æ­£ç‚¹ 2: ãƒœã‚¿ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’å¤‰æ›´ â–¼â–¼â–¼ ---
        if st.button("å‡ºåŠ›å®Ÿè¡Œ", type="primary"):
        # --- â–²â–²â–² ä¿®æ­£ç‚¹ 2 â–²â–²â–² ---
            
            try:
                # --- 1. S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¨å®›å…ˆã®æº–å‚™ ---
                s3_client = get_s3_client()
                if s3_client is None: st.stop()
                
                conn = st.connection("snowflake")
                account_name = get_snowflake_account(conn)
                s3_bucket, s3_key_prefix = get_s3_destination(account_name)
                
                if not s3_bucket:
                    st.error("S3ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆã‚’æ±ºå®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    st.stop()

                # --- 2. SQLã®å…¨ä»¶å–å¾— ---
                spinner_msg = "å…¨ä»¶ãƒ‡ãƒ¼ã‚¿ã‚’Snowflakeã‹ã‚‰å–å¾—ä¸­ã§ã™..."
                if st.session_state.has_more_than_100:
                    spinner_msg = "å…¨ä»¶ãƒ‡ãƒ¼ã‚¿ï¼ˆ100ä»¶è¶…ï¼‰ã‚’Snowflakeã‹ã‚‰å–å¾—ä¸­ã§ã™..."

                with st.spinner(spinner_msg):
                    df_to_upload = conn.query(st.session_state.sql_query)
                
                st.success(f"å…¨ **{len(df_to_upload)}** ä»¶ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†ã€‚")

                # --- 3. æ‹¡å¼µå­ã¨ãƒ•ã‚¡ã‚¤ãƒ«åã®æ±ºå®š ---
                if file_format == "CSV": extension = ".csv"
                elif file_format == "Excel": extension = ".xlsx"
                elif file_format == "TSV": extension = ".tsv"
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_name = f"sql_export_{timestamp}{extension}"
                s3_key = os.path.join(s3_key_prefix, file_name)

                # --- 4. ãƒ‡ãƒ¼ã‚¿å¤‰æ› (ã‚ªãƒ—ã‚·ãƒ§ãƒ³é©ç”¨) ---
                with st.spinner(f"ãƒ‡ãƒ¼ã‚¿ã‚’ {file_format} å½¢å¼ã«å¤‰æ›ä¸­..."):
                    output_buffer = io.BytesIO()
                    
                    if file_format == "CSV":
                        df_to_upload.to_csv(
                            output_buffer, 
                            index=False, 
                            encoding='utf-8-sig',
                            header=include_header, 
                            quoting=quoting 
                        )
                    elif file_format == "TSV":
                        df_to_upload.to_csv(
                            output_buffer, 
                            sep='\t', 
                            index=False, 
                            encoding='utf-8-sig',
                            header=include_header, 
                            quoting=quoting 
                        )
                    elif file_format == "Excel":
                        with pd.ExcelWriter(output_buffer, engine='openpyxl') as writer:
                            df_to_upload.to_excel(writer, index=False, sheet_name='Sheet1')
                    
                    data_to_upload = output_buffer.getvalue()

                # --- 5. S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
                s3_path_full = f"s3://{s3_bucket}/{s3_key}"
                with st.spinner(f"S3 ({s3_path_full}) ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã§ã™..."):
                    s3_client.put_object(
                        Bucket=s3_bucket,
                        Key=s3_key,
                        Body=data_to_upload
                    )
                
                st.success(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼ âœ¨")
                st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹:** `{s3_path_full}`")
                
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ãƒªã‚»ãƒƒãƒˆ
                st.session_state.step = 1
                st.session_state.sql_query = ""
                st.session_state.preview_df = pd.DataFrame()
                st.session_state.preview_count = 0
                st.session_state.has_more_than_100 = False
                st.balloons() 

            except Exception as e:
                st.error(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")

# =============================================================================
# ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯
# =============================================================================

if st.session_state.step == 1:
    step1_sql_input()
elif st.session_state.step == 2:
    step2_format_and_upload()
